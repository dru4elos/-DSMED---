## Задача 
## «Проектное исследование на основе открытых данных в области биомедицины»
### Цель
Применение как классических методов машинного обучения, так и глубокого обучения для достижения наилучших результатов в предсказании наличия или отсутствия одного из 42 заболеваний на основе анализа 132 симптомов. Набор данных состоит двух датасетов: набор для обучения **training.csv** и набор для тестирования модели **testing.csv**.
### Описание данных:
Каждый файл CSV содержит 133 столбца, из которых 132 — это симптомы различных заболеваний, а последний столбец — прогноз заболевания (представлена 41 нозология). 

Проблема классификации данных с наличием нескольких классов может решаться путем предварительной обработки данных (укрупнения классов, например). Если это невозможно из-за характера данных, тогда применяются модели машинного обучения с расширениями для обработки мультитаргетов (skilearn.multiclass) или модели, способные обрабатывать мультитаргеты напрямую(XGBClassifaier).

Необходимо обучить модели на обучающих данных с учетом наличия мультитаргета и протестировать на тестовых данных.
## Используемые Библиотеки
1) pandas
2) numpy
3) matplotlib
4) seaborn
## Библиотеки для машинного обучения
1) sklearn
2) xgboost
3) SVM
4) sklearn.multiclass - OneVsRestClassifier
## Бибиотеки для глубокой нейронной сети
1) tensorflow 
## Результаты и выводы


Тем не менее, небольшое падение метрик CBC может означать, что данная модель может лучше генерализоваться для немного отличающихся наборов данных по сравнению с SVM c One-vs-RestClassifier.


### Модель SVM (support vector machine) с использованием дизайна классификатора One-vs-Rest для работы с мультиклассом.
Accuracy, Precision, Recall и F1-score все равны 1.0 (100%), что означает, что каждый тестовый экземпляр был правильно классифицирован. Confusion Matrix не подтверждает никаких ошибочных классификаций.
Модель машинного обучения SVM работает отлично на тестовом наборе данных. Стратегия One-vs-Rest с SVM эффективна при обучении при наличии мультиклассовой целевой переменной. 


### Модель CBC (CatBoostClassifier).
Модель машинного обучения CBC показала метрики немного ниже, чем модель SVM: Accuracy: 97.6%, Precision: 98.8%, Recall: 97.6%, F1-score: 97.6%. 
Тем не менее, небольшое падение метрик CBC может означать, что данная модель может лучше генерализоваться для немного отличающихся наборов данных по сравнению с SVM c One-vs-RestClassifier.


### Модель CBC (CatBoostClassifier).
Модель машинного обучения CBC показала метрики немного ниже, чем модель SVM: Accuracy: 97.6%, Precision: 98.8%, Recall: 97.6%, F1-score: 97.6%. 
Тем не менее, необходимо опробирование модели на наборах данных, представляющих действительно реальные сценарии.


### Глубокое обучение для мультклассовой классификации.
Для прогнозирования 42 заболеваний по 131 бинарному признаку использовалась архитектура нейросети из класса Visual Transformer.
Из базовой архитектуры ViT были исключёны блоки отвечающие за разбиение изображений на патчи и енкодирования эмбедингов положения патчей в изображении.
Из гиперпараметров были заданы следующие значения:
Количество слоёв: 2
Количество голов само-внимания: 8
Количество ключей внимания для голов: 64
Количество обнуляемых нейронов для устранения переобучения: 40%
Точность модели глубокого обучения на тестовом датасете составила 98%.
Модель несколько хуже предсказывает заболевания по сравнению с SVM, однако превосходит по результатам модели CatBoost и XGBoost

